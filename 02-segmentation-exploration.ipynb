{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 02 \u2014 Segmentation Dataset Exploration: RiceSEG for Rice Field Weed Detection\n\n**Purpose:** Explore the RiceSEG dataset before training a segmentation model (DeepLabV3+).  \n**Runtime:** CPU only \u2014 no GPU needed. Save your GPU hours for training notebooks.  \n**Platform:** Works on both Kaggle and Google Colab.\n\n## What This Notebook Covers\n\n1. **Load RiceSEG** \u2014 discover dataset structure, build image-mask pairs\n2. **Mask analysis** \u2014 class pixel distribution, class weights, per-country breakdown\n3. **Weed pixel analysis** \u2014 how sparse are weeds? Which images are most useful?\n4. **Sample visualization** \u2014 images, masks, and color-coded overlays\n5. **Image properties** \u2014 dimensions, mask values, file sizes\n6. **Training recommendations** \u2014 loss function, augmentation, expected baseline\n\n### About RiceSEG\n\n| Property | Value |\n|----------|-------|\n| **Images** | ~3,078 |\n| **Resolution** | 512x512 pixels |\n| **Classes** | 6: Background, Green vegetation, Senescent vegetation, Panicle, Weeds, Duckweed |\n| **Countries** | China, Japan, India, Philippines, Tanzania |\n| **Format** | Image + pixel-level mask pairs |\n| **Relevance** | Rice field weeds \u2014 the Philippines subset is closest to Indonesian conditions |\n\n> **Key challenge:** Weed pixels are sparse (~1.6%) due to herbicide use at collection sites. This means class-weighted or focal loss is critical for training."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 1. Platform Detection & Setup\n\nSame pattern as notebook 01 \u2014 detect Kaggle vs Colab vs local."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import os\nimport sys\n\n# --- Platform Detection ---\nIS_KAGGLE = os.path.exists('/kaggle/input')\n\ntry:\n    import google.colab\n    IS_COLAB = True\nexcept ImportError:\n    IS_COLAB = False\n\nIS_LOCAL = not IS_KAGGLE and not IS_COLAB\n\nPLATFORM = 'kaggle' if IS_KAGGLE else ('colab' if IS_COLAB else 'local')\nprint(f'Platform detected: {PLATFORM}')\nprint(f'Python version: {sys.version}')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Install Dependencies\n\nLightweight exploration \u2014 only needs PIL for image loading, matplotlib for visualization."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import subprocess\nsubprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'Pillow'])\n\nprint('Dependencies ready.')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nfrom pathlib import Path\nfrom PIL import Image\nfrom collections import Counter\nimport json\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Consistent plot style\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.rcParams['figure.dpi'] = 100\nplt.rcParams['font.size'] = 11\n\nprint('Imports ready.')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 2. Load RiceSEG Dataset\n\n### Dataset Structure\n\nRiceSEG organizes data by country/region, with image-mask pairs. The expected structure varies, but typically:\n\n```\nriceseg/\n  images/\n    *.png or *.jpg\n  masks/ (or labels/ or annotations/)\n    *.png\n```\n\nOr organized by country:\n\n```\nriceseg/\n  China/\n    images/ + masks/\n  Philippines/\n    images/ + masks/\n```\n\n### Class Definitions\n\n| Class ID | Name | Color (for overlay) |\n|----------|------|---------------------|\n| 0 | Background | Black |\n| 1 | Green vegetation | Green |\n| 2 | Senescent vegetation | Yellow |\n| 3 | Panicle | Orange |\n| 4 | **Weeds** | Red |\n| 5 | **Duckweed** | Blue |\n\nClasses 4 and 5 are our primary targets \u2014 everything else is context."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# --- RiceSEG class definitions ---\nRICESEG_CLASSES = {\n    0: 'Background',\n    1: 'Green vegetation',\n    2: 'Senescent vegetation',\n    3: 'Panicle',\n    4: 'Weeds',\n    5: 'Duckweed',\n}\nNUM_CLASSES = len(RICESEG_CLASSES)\n\n# Colors for overlay visualization (RGBA)\nCLASS_COLORS = {\n    0: (0, 0, 0, 0),          # Background \u2014 transparent\n    1: (0, 200, 0, 128),      # Green vegetation\n    2: (200, 200, 0, 128),    # Senescent vegetation\n    3: (255, 165, 0, 128),    # Panicle \u2014 orange\n    4: (255, 0, 0, 180),      # Weeds \u2014 red (highlighted)\n    5: (0, 100, 255, 180),    # Duckweed \u2014 blue (highlighted)\n}\n\n# --- Set data path ---\nif IS_KAGGLE:\n    DATA_ROOT = Path('/kaggle/input/riceseg')\nelif IS_COLAB:\n    DATA_ROOT = Path('/content/riceseg')\nelse:\n    DATA_ROOT = Path('./data/riceseg')\n\nprint(f'Data root: {DATA_ROOT}')\nprint(f'Exists: {DATA_ROOT.exists()}')\n\nif not DATA_ROOT.exists():\n    print()\n    print('=' * 60)\n    print('RICESEG NOT FOUND \u2014 Setup Instructions')\n    print('=' * 60)\n    print('RiceSEG is hosted on HuggingFace, NOT Kaggle.')\n    print()\n    print('Option 1: Upload to Kaggle as private dataset')\n    print('  1. Download from HuggingFace (search: \"RiceSEG\")')\n    print('  2. Go to kaggle.com > Datasets > New Dataset')\n    print('  3. Upload the extracted folder, name it \"riceseg\"')\n    print('  4. Attach to this notebook via \"Add Data\"')\n    print()\n    print('Option 2: For Colab/local')\n    print(f'  Download and extract to: {DATA_ROOT}')\n    print('=' * 60)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# --- Discover dataset structure ---\nif DATA_ROOT.exists():\n    contents = sorted(DATA_ROOT.iterdir())\n    print(f'Contents of {DATA_ROOT}:')\n    for item in contents[:30]:\n        kind = 'DIR' if item.is_dir() else f'FILE ({item.suffix})'\n        if item.is_dir():\n            sub_count = sum(1 for _ in item.iterdir())\n            print(f'  {kind}: {item.name}/ ({sub_count} items)')\n        else:\n            size = item.stat().st_size / 1024\n            print(f'  {kind}: {item.name} \u2014 {size:.1f} KB')\n    \n    if len(contents) > 30:\n        print(f'  ... and {len(contents) - 30} more items')\n    \n    # Count all image and mask files\n    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}\n    all_files = list(DATA_ROOT.rglob('*'))\n    all_images = [f for f in all_files if f.suffix.lower() in image_extensions]\n    \n    print(f'\\nTotal files: {len(all_files)}')\n    print(f'Image/mask files: {len(all_images)}')\n    \n    # Show directory tree (2 levels)\n    print(f'\\nDirectory tree:')\n    for d in sorted(DATA_ROOT.rglob('*')):\n        if d.is_dir():\n            depth = len(d.relative_to(DATA_ROOT).parts)\n            if depth <= 2:\n                indent = '  ' * depth\n                sub_files = sum(1 for f in d.iterdir() if f.is_file())\n                sub_dirs = sum(1 for f in d.iterdir() if f.is_dir())\n                print(f'{indent}{d.name}/ ({sub_files} files, {sub_dirs} subdirs)')\nelse:\n    print('Data root does not exist. Follow setup instructions above.')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Build Image-Mask Pairs\n\nWe need to match each image to its corresponding segmentation mask. The pairing logic depends on the directory structure \u2014 images and masks usually share the same filename but live in different folders (e.g., `images/001.png` \u2194 `masks/001.png`)."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def find_image_mask_pairs(data_root):\n    \"\"\"Find image-mask pairs in the dataset.\n    \n    Tries multiple common structures:\n    1. images/ + masks/ (or labels/, annotations/)\n    2. country/images/ + country/masks/\n    3. Paired by filename across directories\n    \n    Returns: list of dicts with image_path, mask_path, country (if available)\n    \"\"\"\n    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}\n    mask_dir_names = {'masks', 'mask', 'labels', 'label', 'annotations', 'annotation', 'gt', 'groundtruth'}\n    image_dir_names = {'images', 'image', 'img', 'rgb', 'input'}\n    \n    pairs = []\n    \n    # Strategy 1: Top-level images/ + masks/\n    for img_dir_name in image_dir_names:\n        img_dir = data_root / img_dir_name\n        if not img_dir.exists():\n            continue\n        for mask_dir_name in mask_dir_names:\n            mask_dir = data_root / mask_dir_name\n            if not mask_dir.exists():\n                continue\n            \n            for img_file in sorted(img_dir.rglob('*')):\n                if img_file.suffix.lower() not in image_extensions:\n                    continue\n                # Try matching mask with same stem\n                for ext in image_extensions:\n                    mask_candidate = mask_dir / (img_file.stem + ext)\n                    if mask_candidate.exists():\n                        pairs.append({\n                            'image_path': str(img_file),\n                            'mask_path': str(mask_candidate),\n                            'country': 'unknown',\n                        })\n                        break\n    \n    if pairs:\n        return pairs\n    \n    # Strategy 2: country/images/ + country/masks/\n    for country_dir in sorted(data_root.iterdir()):\n        if not country_dir.is_dir():\n            continue\n        \n        for img_dir_name in image_dir_names:\n            img_dir = country_dir / img_dir_name\n            if not img_dir.exists():\n                continue\n            for mask_dir_name in mask_dir_names:\n                mask_dir = country_dir / mask_dir_name\n                if not mask_dir.exists():\n                    continue\n                \n                for img_file in sorted(img_dir.rglob('*')):\n                    if img_file.suffix.lower() not in image_extensions:\n                        continue\n                    for ext in image_extensions:\n                        mask_candidate = mask_dir / (img_file.stem + ext)\n                        if mask_candidate.exists():\n                            pairs.append({\n                                'image_path': str(img_file),\n                                'mask_path': str(mask_candidate),\n                                'country': country_dir.name,\n                            })\n                            break\n    \n    if pairs:\n        return pairs\n    \n    # Strategy 3: Find all images and try to match with nearby masks\n    all_images = sorted(f for f in data_root.rglob('*') \n                       if f.suffix.lower() in image_extensions)\n    \n    # Group by parent directory\n    by_dir = {}\n    for img in all_images:\n        by_dir.setdefault(str(img.parent), []).append(img)\n    \n    # For each directory, try to find a sibling mask directory\n    for dir_path, imgs in by_dir.items():\n        dir_p = Path(dir_path)\n        parent = dir_p.parent\n        dir_lower = dir_p.name.lower()\n        \n        # Skip if this IS a mask directory\n        if dir_lower in mask_dir_names:\n            continue\n        \n        # Look for sibling mask directory\n        for mask_dir_name in mask_dir_names:\n            mask_dir = parent / mask_dir_name\n            if mask_dir.exists():\n                for img_file in imgs:\n                    for ext in image_extensions:\n                        mask_candidate = mask_dir / (img_file.stem + ext)\n                        if mask_candidate.exists():\n                            # Try to determine country from path\n                            rel = img_file.relative_to(data_root)\n                            country = rel.parts[0] if len(rel.parts) > 2 else 'unknown'\n                            pairs.append({\n                                'image_path': str(img_file),\n                                'mask_path': str(mask_candidate),\n                                'country': country,\n                            })\n                            break\n    \n    return pairs\n\n\n# Build pairs\nif DATA_ROOT.exists():\n    pairs = find_image_mask_pairs(DATA_ROOT)\n    df = pd.DataFrame(pairs)\n    \n    print(f'Found {len(df)} image-mask pairs')\n    if len(df) > 0:\n        print(f'\\nCountry distribution:')\n        print(df['country'].value_counts().to_string())\n        print(f'\\nSample pairs:')\n        display(df.head(10))\n    else:\n        print('No pairs found. Check the directory structure above.')\n        print('You may need to adjust the pairing logic for this dataset version.')\nelse:\n    df = None\n    print('Data root not found. Cannot load pairs.')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 3. Mask Analysis\n\n### Understanding Segmentation Masks\n\nEach mask is an image where pixel values represent class IDs (0-5). Let's verify the mask values match our expected class definitions and measure the class distribution across the entire dataset."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "if df is not None and len(df) > 0:\n    # Analyze class distribution across ALL masks\n    # (This may take a few minutes for 3K+ masks)\n    \n    class_pixel_counts = np.zeros(NUM_CLASSES, dtype=np.int64)\n    images_with_class = np.zeros(NUM_CLASSES, dtype=np.int64)  # How many images contain each class\n    total_pixels = 0\n    mask_values_seen = set()\n    errors = []\n    \n    print(f'Analyzing {len(df)} masks (this may take a minute)...')\n    \n    for i, (_, row) in enumerate(df.iterrows()):\n        try:\n            mask = np.array(Image.open(row['mask_path']))\n            \n            # Track unique values\n            unique_vals = np.unique(mask)\n            mask_values_seen.update(unique_vals.tolist())\n            \n            # Count pixels per class\n            for cls_id in range(NUM_CLASSES):\n                count = np.sum(mask == cls_id)\n                class_pixel_counts[cls_id] += count\n                if count > 0:\n                    images_with_class[cls_id] += 1\n            \n            total_pixels += mask.size\n            \n        except Exception as e:\n            errors.append((row['mask_path'], str(e)))\n        \n        if (i + 1) % 500 == 0:\n            print(f'  Processed {i + 1}/{len(df)} masks...')\n    \n    print(f'\\nDone! Analyzed {len(df) - len(errors)} masks ({len(errors)} errors)')\n    print(f'\\nUnique mask values seen: {sorted(mask_values_seen)}')\n    print(f'Expected class IDs: {list(range(NUM_CLASSES))}')\n    \n    # Unexpected values?\n    expected = set(range(NUM_CLASSES))\n    unexpected = mask_values_seen - expected\n    if unexpected:\n        print(f'Unexpected mask values: {sorted(unexpected)}')\n        print('These may represent additional classes or encoding artifacts.')\n    \n    # Class pixel distribution\n    print(f'\\n=== Class Pixel Distribution ===')\n    print(f'Total pixels analyzed: {total_pixels:,}')\n    for cls_id in range(NUM_CLASSES):\n        pct = class_pixel_counts[cls_id] / total_pixels * 100\n        img_pct = images_with_class[cls_id] / len(df) * 100\n        print(f'  {RICESEG_CLASSES[cls_id]:25s}: {class_pixel_counts[cls_id]:>12,} pixels ({pct:5.2f}%) \u2014 in {images_with_class[cls_id]:,} images ({img_pct:.1f}%)')\nelse:\n    print('No data to analyze.')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Plot class pixel distribution\nif df is not None and len(df) > 0 and total_pixels > 0:\n    class_names_list = [RICESEG_CLASSES[i] for i in range(NUM_CLASSES)]\n    class_pcts = class_pixel_counts / total_pixels * 100\n    \n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    \n    # Bar chart\n    bar_colors = ['#333333', '#2ca02c', '#bcbd22', '#ff7f0e', '#d62728', '#1f77b4']\n    bars = axes[0].barh(class_names_list, class_pcts, color=bar_colors)\n    axes[0].set_xlabel('Pixel Percentage (%)')\n    axes[0].set_title('Class Distribution (by pixel count)')\n    for bar, pct in zip(bars, class_pcts):\n        axes[0].text(bar.get_width() + 0.2, bar.get_y() + bar.get_height()/2,\n                     f'{pct:.2f}%', va='center', fontsize=10)\n    \n    # Pie chart (exclude background for clarity)\n    fg_counts = class_pixel_counts[1:]  # Skip background\n    fg_names = class_names_list[1:]\n    fg_colors = bar_colors[1:]\n    axes[1].pie(fg_counts, labels=fg_names, colors=fg_colors,\n                autopct='%1.1f%%', startangle=90, textprops={'fontsize': 10})\n    axes[1].set_title('Foreground Class Proportions\\n(excluding background)')\n    \n    plt.suptitle('RiceSEG \u2014 Class Pixel Distribution', fontsize=14, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\n    \n    # Compute class weights (inverse frequency, for training)\n    # Exclude zero-count classes to avoid division by zero\n    nonzero = class_pixel_counts > 0\n    class_weights = np.zeros(NUM_CLASSES)\n    if nonzero.any():\n        freq = class_pixel_counts[nonzero] / total_pixels\n        weights = 1.0 / freq\n        weights = weights / weights.mean()  # Normalize so mean weight = 1\n        class_weights[nonzero] = weights\n    \n    print('\\n=== Recommended Class Weights (for weighted loss) ===')\n    for cls_id in range(NUM_CLASSES):\n        print(f'  {RICESEG_CLASSES[cls_id]:25s}: weight = {class_weights[cls_id]:.2f}')\n    \n    weed_weight = class_weights[4] if 4 < len(class_weights) else 0\n    print(f'\\nWeed class weight: {weed_weight:.1f}x \u2014 this is how much the loss should penalize weed misclassifications')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Per-country distribution\nif df is not None and len(df) > 0 and df['country'].nunique() > 1:\n    countries = sorted(df['country'].unique())\n    country_stats = {}\n    \n    for country in countries:\n        country_df = df[df['country'] == country]\n        country_pixels = np.zeros(NUM_CLASSES, dtype=np.int64)\n        total = 0\n        \n        for _, row in country_df.iterrows():\n            try:\n                mask = np.array(Image.open(row['mask_path']))\n                for cls_id in range(NUM_CLASSES):\n                    country_pixels[cls_id] += np.sum(mask == cls_id)\n                total += mask.size\n            except Exception:\n                pass\n        \n        if total > 0:\n            country_stats[country] = {\n                'count': len(country_df),\n                'class_pcts': country_pixels / total * 100,\n            }\n    \n    if country_stats:\n        # Plot per-country class distribution\n        fig, ax = plt.subplots(figsize=(14, 6))\n        \n        x = np.arange(len(country_stats))\n        width = 0.12\n        bar_colors = ['#333333', '#2ca02c', '#bcbd22', '#ff7f0e', '#d62728', '#1f77b4']\n        \n        for cls_id in range(NUM_CLASSES):\n            values = [country_stats[c]['class_pcts'][cls_id] for c in country_stats]\n            ax.bar(x + cls_id * width, values, width, \n                   label=RICESEG_CLASSES[cls_id], color=bar_colors[cls_id])\n        \n        ax.set_xlabel('Country')\n        ax.set_ylabel('Pixel Percentage (%)')\n        ax.set_title('Class Distribution by Country')\n        ax.set_xticks(x + width * (NUM_CLASSES - 1) / 2)\n        ax.set_xticklabels([f'{c}\\n(n={country_stats[c][\"count\"]})' for c in country_stats])\n        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n        \n        plt.tight_layout()\n        plt.show()\n        \n        # Highlight Philippines (most relevant)\n        if 'Philippines' in country_stats:\n            ph = country_stats['Philippines']\n            print(f'\\n=== Philippines Subset (most relevant for Indonesia) ===')\n            print(f'Images: {ph[\"count\"]}')\n            for cls_id in range(NUM_CLASSES):\n                print(f'  {RICESEG_CLASSES[cls_id]:25s}: {ph[\"class_pcts\"][cls_id]:.2f}%')\nelse:\n    print('Single country or no country metadata \u2014 skipping per-country analysis.')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Interpretation \u2014 Class Imbalance\n\nThe weed pixel distribution reveals a key training challenge:\n\n**Weed pixels are very sparse** (~1-2% of total pixels). This means:\n- A naive model can achieve >98% pixel accuracy by predicting \"not weed\" everywhere\n- Standard cross-entropy loss will ignore weeds in favor of majority classes\n- **Focal loss** or **heavily weighted cross-entropy** is critical\n\n**Training implications:**\n- Use focal loss (gamma=2) or weighted CE with weed class weight 10-20x\n- Consider oversampling images that actually contain weed pixels\n- Monitor **weed-class IoU** separately \u2014 overall IoU will be misleading\n- The Philippines subset may have different weed proportions \u2014 evaluate separately"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Analyze which images contain weed pixels (class 4 and 5)\nif df is not None and len(df) > 0:\n    weed_info = []\n    \n    for _, row in df.iterrows():\n        try:\n            mask = np.array(Image.open(row['mask_path']))\n            weed_pixels = np.sum(mask == 4)\n            duckweed_pixels = np.sum(mask == 5)\n            total = mask.size\n            \n            weed_info.append({\n                'image_path': row['image_path'],\n                'mask_path': row['mask_path'],\n                'country': row['country'],\n                'weed_pixels': weed_pixels,\n                'duckweed_pixels': duckweed_pixels,\n                'weed_pct': weed_pixels / total * 100,\n                'duckweed_pct': duckweed_pixels / total * 100,\n                'any_weed': weed_pixels > 0 or duckweed_pixels > 0,\n            })\n        except Exception:\n            pass\n    \n    weed_df = pd.DataFrame(weed_info)\n    \n    with_weed = weed_df['any_weed'].sum()\n    total_imgs = len(weed_df)\n    \n    print(f'=== Weed Pixel Analysis ===')\n    print(f'Total images: {total_imgs}')\n    print(f'Images WITH any weed/duckweed pixels: {with_weed} ({with_weed/total_imgs*100:.1f}%)')\n    print(f'Images WITHOUT weed pixels: {total_imgs - with_weed} ({(total_imgs - with_weed)/total_imgs*100:.1f}%)')\n    \n    # Distribution of weed pixel area\n    weed_present = weed_df[weed_df['any_weed']]\n    if len(weed_present) > 0:\n        print(f'\\nAmong images WITH weeds:')\n        print(f'  Mean weed area: {weed_present[\"weed_pct\"].mean():.2f}%')\n        print(f'  Max weed area:  {weed_present[\"weed_pct\"].max():.2f}%')\n        print(f'  Mean duckweed area: {weed_present[\"duckweed_pct\"].mean():.2f}%')\n        print(f'  Max duckweed area:  {weed_present[\"duckweed_pct\"].max():.2f}%')\n        \n        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n        \n        axes[0].hist(weed_present['weed_pct'], bins=30, color='#d62728', edgecolor='white', alpha=0.8)\n        axes[0].set_xlabel('Weed Pixel Percentage (%)')\n        axes[0].set_ylabel('Number of Images')\n        axes[0].set_title(f'Weed Pixel Area Distribution\\n(n={len(weed_present)} images with weeds)')\n        \n        axes[1].hist(weed_present['duckweed_pct'], bins=30, color='#1f77b4', edgecolor='white', alpha=0.8)\n        axes[1].set_xlabel('Duckweed Pixel Percentage (%)')\n        axes[1].set_ylabel('Number of Images')\n        axes[1].set_title(f'Duckweed Pixel Area Distribution\\n(n={len(weed_present)} images with duckweed)')\n        \n        plt.suptitle('Weed Pixel Area Distribution (images with weeds only)', fontsize=13, fontweight='bold')\n        plt.tight_layout()\n        plt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 4. Sample Visualization\n\nLet's inspect image-mask pairs visually. We'll show:\n- Original image\n- Segmentation mask (class IDs as grayscale)\n- Color-coded overlay (mask on top of image)\n\nWe prioritize samples that **contain weed/duckweed pixels** \u2014 since most images have none, random sampling would show mostly empty masks."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def create_overlay(image, mask, class_colors, alpha=0.5):\n    \"\"\"Create a color-coded overlay of the mask on the image.\"\"\"\n    img_arr = np.array(image.convert('RGB')).astype(np.float32)\n    overlay = np.zeros((*mask.shape, 4), dtype=np.float32)\n    \n    for cls_id, color in class_colors.items():\n        cls_mask = mask == cls_id\n        if cls_mask.any():\n            overlay[cls_mask] = [c / 255.0 for c in color]\n    \n    # Blend: where overlay has alpha, mix image and overlay color\n    result = img_arr.copy()\n    for c in range(3):\n        mask_alpha = overlay[:, :, 3]\n        result[:, :, c] = (1 - mask_alpha * alpha) * img_arr[:, :, c] + mask_alpha * alpha * overlay[:, :, c] * 255\n    \n    return np.clip(result, 0, 255).astype(np.uint8)\n\n\nif df is not None and len(df) > 0:\n    # Select samples WITH weed pixels (more interesting)\n    if 'weed_df' in dir() and len(weed_df[weed_df['any_weed']]) > 0:\n        weed_samples = weed_df[weed_df['any_weed']].nlargest(12, 'weed_pct')\n    else:\n        weed_samples = df.sample(n=min(12, len(df)), random_state=42)\n    \n    n_samples = min(4, len(weed_samples))\n    fig, axes = plt.subplots(n_samples, 3, figsize=(15, 4 * n_samples))\n    if n_samples == 1:\n        axes = axes.reshape(1, -1)\n    \n    for row_idx, (_, sample) in enumerate(weed_samples.head(n_samples).iterrows()):\n        img_path = sample.get('image_path', sample.get('image_path'))\n        mask_path = sample.get('mask_path', sample.get('mask_path'))\n        \n        img = Image.open(img_path).convert('RGB')\n        mask = np.array(Image.open(mask_path))\n        \n        # Original image\n        axes[row_idx, 0].imshow(img)\n        axes[row_idx, 0].set_title('Image', fontsize=10)\n        axes[row_idx, 0].axis('off')\n        \n        # Mask (class IDs)\n        axes[row_idx, 1].imshow(mask, cmap='tab10', vmin=0, vmax=NUM_CLASSES - 1)\n        axes[row_idx, 1].set_title('Mask (class IDs)', fontsize=10)\n        axes[row_idx, 1].axis('off')\n        \n        # Color overlay\n        overlay = create_overlay(img, mask, CLASS_COLORS)\n        axes[row_idx, 2].imshow(overlay)\n        country = sample.get('country', '?')\n        weed_pct = sample.get('weed_pct', 0)\n        axes[row_idx, 2].set_title(f'Overlay \u2014 {country} (weed: {weed_pct:.1f}%)', fontsize=10)\n        axes[row_idx, 2].axis('off')\n    \n    plt.suptitle('RiceSEG \u2014 Images with Highest Weed Content', fontsize=14, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\n    \n    # Legend\n    print('Color legend:')\n    for cls_id, name in RICESEG_CLASSES.items():\n        r, g, b, _ = CLASS_COLORS[cls_id]\n        print(f'  Class {cls_id}: {name} \u2014 RGB({r}, {g}, {b})')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Show Philippines-only subset (most relevant to Indonesia)\nif df is not None and len(df) > 0 and 'country' in df.columns:\n    ph_df = df[df['country'].str.lower().str.contains('phil', na=False)]\n    \n    if len(ph_df) > 0:\n        print(f'Philippines subset: {len(ph_df)} images')\n        \n        # Find Philippines images with weeds\n        if 'weed_df' in dir():\n            ph_weed = weed_df[weed_df['country'].str.lower().str.contains('phil', na=False) & weed_df['any_weed']]\n        else:\n            ph_weed = ph_df.sample(n=min(4, len(ph_df)), random_state=42)\n        \n        n_ph = min(4, len(ph_weed))\n        if n_ph > 0:\n            fig, axes = plt.subplots(n_ph, 3, figsize=(15, 4 * n_ph))\n            if n_ph == 1:\n                axes = axes.reshape(1, -1)\n            \n            for row_idx, (_, sample) in enumerate(ph_weed.head(n_ph).iterrows()):\n                img = Image.open(sample['image_path']).convert('RGB')\n                mask = np.array(Image.open(sample['mask_path']))\n                overlay = create_overlay(img, mask, CLASS_COLORS)\n                \n                axes[row_idx, 0].imshow(img)\n                axes[row_idx, 0].set_title('Image', fontsize=10)\n                axes[row_idx, 0].axis('off')\n                \n                axes[row_idx, 1].imshow(mask, cmap='tab10', vmin=0, vmax=NUM_CLASSES - 1)\n                axes[row_idx, 1].set_title('Mask', fontsize=10)\n                axes[row_idx, 1].axis('off')\n                \n                axes[row_idx, 2].imshow(overlay)\n                axes[row_idx, 2].set_title('Overlay', fontsize=10)\n                axes[row_idx, 2].axis('off')\n            \n            plt.suptitle('Philippines Subset \u2014 Most Relevant to Indonesian Conditions', \n                         fontsize=14, fontweight='bold')\n            plt.tight_layout()\n            plt.show()\n        else:\n            print('No Philippines images with weed pixels found.')\n    else:\n        print('No Philippines subset found in the country metadata.')\n        print(f'Available countries: {df[\"country\"].unique().tolist()}')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Visual Observations Checklist\n\nAfter looking at the samples above, note:\n\n- [ ] **Mask quality:** Are boundaries between classes smooth or jagged?\n- [ ] **Weed appearance:** What do weeds look like in these images? Color, shape, texture?\n- [ ] **Mask alignment:** Do masks align well with visible features in the images?\n- [ ] **Philippines subset:** How do Philippines images compare to what you'd expect in Indonesian rice fields?\n- [ ] **Duckweed vs weeds:** Can you visually distinguish duckweed (floating, green) from terrestrial weeds?"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Image dimension analysis\nif df is not None and len(df) > 0:\n    sample_check = df.sample(n=min(200, len(df)), random_state=42)\n    \n    widths, heights, mask_shapes = [], [], []\n    file_sizes = []\n    \n    for _, row in sample_check.iterrows():\n        try:\n            img = Image.open(row['image_path'])\n            w, h = img.size\n            widths.append(w)\n            heights.append(h)\n            file_sizes.append(Path(row['image_path']).stat().st_size / 1024)\n            \n            mask = Image.open(row['mask_path'])\n            mask_shapes.append(mask.size)\n        except Exception:\n            pass\n    \n    print(f'=== Image Properties (sample of {len(widths)}) ===')\n    print(f'Width  \u2014 min: {min(widths)}, max: {max(widths)}, unique: {len(set(widths))}')\n    print(f'Height \u2014 min: {min(heights)}, max: {max(heights)}, unique: {len(set(heights))}')\n    print(f'File size \u2014 min: {min(file_sizes):.1f} KB, max: {max(file_sizes):.1f} KB, mean: {np.mean(file_sizes):.1f} KB')\n    \n    # Verify mask dimensions match image dimensions\n    mismatched = sum(1 for i, ms in enumerate(mask_shapes) \n                     if ms != (widths[i], heights[i]))\n    print(f'\\nMask-image dimension mismatches: {mismatched}')\n    if mismatched == 0:\n        print('All masks match their image dimensions.')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Mask value analysis\nif df is not None and len(df) > 0:\n    check_sample = df.sample(n=min(50, len(df)), random_state=42)\n    \n    all_values = set()\n    value_counts = Counter()\n    \n    for _, row in check_sample.iterrows():\n        try:\n            mask = np.array(Image.open(row['mask_path']))\n            vals = np.unique(mask)\n            all_values.update(vals.tolist())\n            for v in vals:\n                value_counts[v] += np.sum(mask == v)\n        except Exception:\n            pass\n    \n    print(f'=== Mask Value Analysis (sample of {len(check_sample)}) ===')\n    print(f'Unique values: {sorted(all_values)}')\n    print(f'\\nValue \u2192 Class mapping:')\n    for val in sorted(all_values):\n        name = RICESEG_CLASSES.get(val, f'UNKNOWN (value={val})')\n        pct = value_counts[val] / sum(value_counts.values()) * 100\n        print(f'  {val} \u2192 {name} ({pct:.2f}%)')\n    \n    # Check mask dtype\n    sample_mask = np.array(Image.open(df.iloc[0]['mask_path']))\n    print(f'\\nMask dtype: {sample_mask.dtype}')\n    print(f'Mask shape: {sample_mask.shape}')\n    print(f'Expected: uint8, (512, 512) or similar single-channel')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# File size distribution\nif df is not None and len(df) > 0 and file_sizes:\n    fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n    \n    axes[0].hist(widths, bins=20, color='steelblue', edgecolor='white')\n    axes[0].set_title('Image Width Distribution')\n    axes[0].set_xlabel('Width (px)')\n    \n    axes[1].hist(heights, bins=20, color='coral', edgecolor='white')\n    axes[1].set_title('Image Height Distribution')\n    axes[1].set_xlabel('Height (px)')\n    \n    axes[2].hist(file_sizes, bins=30, color='mediumseagreen', edgecolor='white')\n    axes[2].set_title('File Size Distribution')\n    axes[2].set_xlabel('Size (KB)')\n    \n    plt.suptitle('RiceSEG \u2014 Image Properties', fontsize=13, fontweight='bold')\n    plt.tight_layout()\n    plt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Summary configuration for training\nif df is not None and len(df) > 0:\n    summary = {\n        'dataset': 'RiceSEG',\n        'task': 'segmentation',\n        'total_images': len(df),\n        'num_classes': NUM_CLASSES,\n        'class_names': RICESEG_CLASSES,\n        'image_size': f'{min(widths)}x{min(heights)}' if len(set(widths)) == 1 and len(set(heights)) == 1 else 'varies',\n        'platform': PLATFORM,\n    }\n    \n    if 'class_weights' in dir():\n        summary['class_weights'] = {RICESEG_CLASSES[i]: round(class_weights[i], 2) for i in range(NUM_CLASSES)}\n    \n    if 'weed_df' in dir():\n        summary['images_with_weeds'] = int(weed_df['any_weed'].sum())\n        summary['weed_pixel_pct'] = round(class_pixel_counts[4] / total_pixels * 100, 3) if total_pixels > 0 else 0\n    \n    print('=== RiceSEG \u2014 Training Configuration Summary ===')\n    print(json.dumps({k: v for k, v in summary.items() if k != 'class_names'}, indent=2))\n    \n    print(f'\\n=== Recommended Training Setup for DeepLabV3+ ===')\n    print(f'Input size: 512x512 (native resolution \u2014 no resize needed)')\n    print(f'Backbone: ResNet-50 (pretrained ImageNet)')\n    print(f'Loss: Focal loss (gamma=2) or weighted cross-entropy')\n    print(f'Weed class weight: 10-20x (compensate for sparse weed pixels)')\n    print(f'Augmentation: flip, rotate, color jitter, random crop 384x384')\n    print(f'Normalize to: ImageNet stats (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 5. Training Recommendations for DeepLabV3+\n\n### Model Configuration\n\n| Parameter | Recommended Value | Reasoning |\n|-----------|-------------------|-----------|\n| **Architecture** | DeepLabV3+ | SOTA for semantic segmentation, good balance of accuracy and speed |\n| **Backbone** | ResNet-50 (ImageNet pretrained) | Enough capacity for 6 classes, not too heavy for Kaggle GPU |\n| **Input size** | 512x512 | Native RiceSEG resolution \u2014 no information loss |\n| **Loss function** | Focal loss (gamma=2) | Handles extreme class imbalance (weeds ~1.6%) |\n| **Class weights** | See summary above | Weed/duckweed classes need 10-20x weight |\n\n### Augmentation Strategy\n\n| Transform | Parameters | Why |\n|-----------|-----------|-----|\n| HorizontalFlip | p=0.5 | Rice fields look same mirrored |\n| VerticalFlip | p=0.5 | Aerial/top-down views are rotation-invariant |\n| RandomRotate90 | p=0.5 | Further rotation invariance |\n| ColorJitter | brightness=0.2, contrast=0.2 | Handle varying lighting conditions |\n| RandomCrop | 384x384 from 512x512 | Augment while keeping enough context |\n\n### Expected Baseline Performance\n\n| Metric | Expected Range | Notes |\n|--------|---------------|-------|\n| Overall mIoU | 40-55% | Averaged across all 6 classes |\n| Weed IoU | 10-30% | Sparse class, hardest to predict |\n| Background IoU | 85-95% | Dominant class, easy to predict |\n| Overall pixel accuracy | >90% | Misleading due to class imbalance |\n\n### Training Strategy\n\n1. **Phase 1:** Freeze backbone, train decoder (5-10 epochs, lr=1e-3)\n2. **Phase 2:** Unfreeze all, fine-tune (10-20 epochs, lr=1e-4)\n3. **Evaluate on:** Weed IoU specifically, not just overall metrics\n4. **Consider:** Philippines-only subset for faster iteration (smaller but most relevant)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 6. What's Next\n\n| Next Step | Notebook | What It Does |\n|-----------|----------|-------------|\n| Train segmentation model | `03-segmentation-baseline.ipynb` (or `05-*`) | Train DeepLabV3+ on RiceSEG |\n| Classification baseline | `04-classification-baseline.ipynb` | Train EfficientNetV2-S on Crop & Weed or Bangladesh data |\n\n**Key inputs from this notebook:**\n- Class weights for weighted loss function\n- Knowledge that weed pixels are sparse (~1.6%)\n- Philippines subset identified as most relevant\n- 512x512 native resolution confirmed\n- Mask format verified (single-channel, integer class IDs)"
  }
 ]
}